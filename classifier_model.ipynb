{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l9CC6_RRCMRl",
        "outputId": "08838b3c-605b-4947-95ef-79e9c9c36add"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=1TG9P5B2k3eTbC4XDxDmEc07dyAORPC16\n",
            "From (redirected): https://drive.google.com/uc?id=1TG9P5B2k3eTbC4XDxDmEc07dyAORPC16&confirm=t&uuid=945dacc8-d02e-4f87-beb1-a062664b379d\n",
            "To: /content/data.zip\n",
            "100%|██████████| 2.28G/2.28G [00:45<00:00, 50.0MB/s]\n",
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=12QrDrLT1F-X7UycvOoApXFqxTw3Zx93K\n",
            "From (redirected): https://drive.google.com/uc?id=12QrDrLT1F-X7UycvOoApXFqxTw3Zx93K&confirm=t&uuid=da6900d4-8326-4b21-a8ac-b14dea677117\n",
            "To: /content/test.zip\n",
            "100%|██████████| 222M/222M [00:03<00:00, 59.8MB/s]\n"
          ]
        }
      ],
      "source": [
        "# !pip install gdown\n",
        "#/////////////////////////////\n",
        "\n",
        "import gdown\n",
        "import shutil\n",
        "import os\n",
        "\n",
        "# URL-адреса для скачивания файлов с Google Drive\n",
        "data_zip_url = \"https://drive.google.com/file/d/1TG9P5B2k3eTbC4XDxDmEc07dyAORPC16/view?usp=sharing\"\n",
        "test_zip_url = \"https://drive.google.com/file/d/12QrDrLT1F-X7UycvOoApXFqxTw3Zx93K/view?usp=sharing\"\n",
        "\n",
        "# Явное указание имен файлов при сохранении\n",
        "data_zip_path = \"/content/data.zip\"\n",
        "test_zip_path = \"/content/test.zip\"\n",
        "\n",
        "# Загрузка и сохранение файлов под указанными именами\n",
        "gdown.download(data_zip_url, data_zip_path, fuzzy=True)\n",
        "gdown.download(test_zip_url, test_zip_path, fuzzy=True)\n",
        "\n",
        "# Распаковка архивов data.zip и test.zip в текущую директорию\n",
        "shutil.unpack_archive(data_zip_path, '.', 'zip')\n",
        "shutil.unpack_archive(test_zip_path, '.', 'zip')\n",
        "\n",
        "# Удаление архивов после распаковки\n",
        "os.remove(data_zip_path)\n",
        "os.remove(test_zip_path)\n",
        "\n",
        "# train.csv - датасет для обучения\n",
        "# sample_submission.csv - пример файла-ответа, который нужно отправить на платформу\n",
        "\n",
        "# Сами изображения находятся по ссылкам:\n",
        "# Обучение - https://drive.google.com/file/d/1TG9P5B2k3eTbC4XDxDmEc07dyAORPC16/view?usp=sharing\n",
        "# Тест - https://drive.google.com/file/d/12QrDrLT1F-X7UycvOoApXFqxTw3Zx93K/view?usp=sharing\n",
        "\n",
        "# Поля в датасетах\n",
        "# image_path - строка, являющаюся путем до изображения в случае обучения или названием изображения в случае теста\n",
        "# emotion - строка, характеризующая эмоцию\n",
        "# В данном задании требуется предсказать 9 базовых эмоций, таких как:\n",
        "# neutral - нейтральная эмоция\n",
        "# anger - гнев, злость\n",
        "# contempt - презрение\n",
        "# disgust - отвращение\n",
        "# fear - страх\n",
        "# happy - веселый\n",
        "# sad - грусть\n",
        "# surprise - удивленность\n",
        "# uncertain - неуверенность\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import models\n",
        "from PIL import Image\n",
        "import gdown\n",
        "import shutil\n",
        "from tqdm import tqdm\n",
        "\n",
        "\n",
        "# маппинг эмоций\n",
        "emotion_labels = {\n",
        "    'anger': 0, 'contempt': 1, 'disgust': 2, 'fear': 3, 'happy': 4,\n",
        "    'neutral': 5, 'sad': 6, 'surprise': 7, 'uncertain': 8\n",
        "}\n",
        "\n",
        "\n",
        "# обработка данных\n",
        "class EmotionDataset(Dataset):\n",
        "    def __init__(self, root_dir, transform=None):\n",
        "        self.root_dir = root_dir\n",
        "        self.transform = transform\n",
        "        self.image_files = []\n",
        "        self.labels = []\n",
        "\n",
        "        # Заполнение списка файлов и меток\n",
        "        for emotion, label in emotion_labels.items():\n",
        "            emotion_dir = os.path.join(root_dir, emotion)\n",
        "            for img_file in os.listdir(emotion_dir):\n",
        "              # Проверка на jpg\n",
        "                if img_file.endswith('.jpg'):\n",
        "                    self.image_files.append(os.path.join(emotion_dir, img_file))\n",
        "                    self.labels.append(label)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_files)\n",
        "\n",
        "    # преобразовать изображение, вернуть его и метку\n",
        "    def __getitem__(self, idx):\n",
        "        img_path = self.image_files[idx]\n",
        "        image = Image.open(img_path).convert(\"RGB\")\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "        label = self.labels[idx]\n",
        "        return image, label\n",
        "\n",
        "# трансформация изображений\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((128, 128)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "# создаем датасет и загрузчик\n",
        "train_dataset = EmotionDataset(root_dir=\"/content/train\", transform=transform)\n",
        "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True, num_workers=4, pin_memory=True)\n",
        "\n",
        "# определяем модель\n",
        "class EmotionClassifier(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(EmotionClassifier, self).__init__()\n",
        "        self.model = models.mobilenet_v2(pretrained=True) # предобученная модель MobileNetV2\n",
        "        self.model.classifier[1] = nn.Linear(self.model.last_channel, 9)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.model(x)\n",
        "\n",
        "model = EmotionClassifier()\n",
        "criterion = nn.CrossEntropyLoss() # функция потерь\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001) # оптимизатор\n",
        "\n",
        "# настройка устройства\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "\n",
        "num_epochs = 3\n",
        "# обучение\n",
        "for epoch in tqdm(range(num_epochs)):\n",
        "    model.train()\n",
        "    for images, labels in train_loader:\n",
        "        images, labels = images.to(device, non_blocking=True), labels.to(device, non_blocking=True)\n",
        "\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "# предсказания на тестовых данных\n",
        "class TestDataset(Dataset):\n",
        "    def __init__(self, root_dir, transform=None):\n",
        "        self.root_dir = root_dir\n",
        "        self.transform = transform\n",
        "        self.image_files = [f for f in os.listdir(root_dir) if f.endswith('.jpg')]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_files)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_path = os.path.join(self.root_dir, self.image_files[idx])\n",
        "        image = Image.open(img_path).convert(\"RGB\")\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "        return image, self.image_files[idx]\n",
        "\n",
        "# создаем датасет и загрузчик уже для тестирования\n",
        "test_dataset = TestDataset(root_dir=\"/content/test_kaggle\", transform=transform)\n",
        "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False, num_workers=4, pin_memory=True)\n",
        "\n",
        "# предсказание\n",
        "model.eval()\n",
        "predictions = []\n",
        "with torch.no_grad():\n",
        "    for images, image_files in test_loader:\n",
        "        images = images.to(device, non_blocking=True)\n",
        "        outputs = model(images)\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        predictions.extend(zip(image_files, predicted.cpu().numpy()))\n",
        "\n",
        "# обратный маппинг меток в эмоции\n",
        "reverse_emotion_labels = {v: k for k, v in emotion_labels.items()}\n",
        "predictions = [(img, reverse_emotion_labels[pred]) for img, pred in predictions]\n",
        "\n",
        "# генерация и сохранения csv файла\n",
        "submission_df = pd.DataFrame(predictions, columns=['image_path', 'emotion'])\n",
        "submission_df.to_csv(\"submission.csv\", index=False)\n",
        "\n",
        "# сохранить модельку\n",
        "torch.save(model.state_dict(), \"emotion_classifier.pth\")\n",
        "\n",
        "# вывод хэда файлв\n",
        "print(submission_df.head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zdn__x9xxgqG",
        "outputId": "4b458fcd-c7ec-4618-f033-8719efb71d12"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=MobileNet_V2_Weights.IMAGENET1K_V1`. You can also use `weights=MobileNet_V2_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/mobilenet_v2-b0353104.pth\" to /root/.cache/torch/hub/checkpoints/mobilenet_v2-b0353104.pth\n",
            "100%|██████████| 13.6M/13.6M [00:00<00:00, 127MB/s]\n",
            "100%|██████████| 3/3 [3:10:04<00:00, 3801.52s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  image_path    emotion\n",
            "0   1093.jpg        sad\n",
            "1    304.jpg        sad\n",
            "2   2077.jpg      happy\n",
            "3   2816.jpg  uncertain\n",
            "4    556.jpg      anger\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "20:40"
      ],
      "metadata": {
        "id": "mOkFXVfvyw1V"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}